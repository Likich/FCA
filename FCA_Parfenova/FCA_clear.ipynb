{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to use the data on Heart disease UCI as the first dataset. This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. The \"goal\" field refers to the presence of heart disease in the patient.<br /> <br />\n",
    "#### Attribute information:<br />\n",
    "age<br />\n",
    "sex<br />\n",
    "chest pain type (4 values)<br />\n",
    "resting blood pressure<br />\n",
    "serum cholestoral in mg/dl<br />\n",
    "fasting blood sugar > 120 mg/dl<br />\n",
    "resting electrocardiographic results (values 0,1,2)<br />\n",
    "maximum heart rate achieved<br />\n",
    "exercise induced angina<br />\n",
    "oldpeak = ST depression induced by exercise relative to rest<br />\n",
    "the slope of the peak exercise ST segment<br />\n",
    "number of major vessels (0-3) colored by flourosopy<br />\n",
    "thal: 3 = normal; 6 = fixed defect; 7 = reversable defect<br />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First of all we need to preprocess our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age_cat'] = pd.qcut(data['age'], 5)\n",
    "data['trestbps_cat'] = pd.qcut(data['trestbps'], 5)\n",
    "data['chol_cat'] = pd.cut(data['chol'], 5)\n",
    "data['thalach_cat'] = pd.cut(data['thalach'], 5)\n",
    "data['oldpeak_cat'] = pd.cut(data['oldpeak'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns = ['slope', 'ca', 'thal', 'cp'])\n",
    "data = data.drop(['age','trestbps','chol','thalach','oldpeak'], 1)\n",
    "data = pd.get_dummies(data, columns=['age_cat', 'trestbps_cat', 'chol_cat', 'thalach_cat', 'oldpeak_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('heart_binary.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "databin = pd.read_csv('heart_binary.csv')\n",
    "features = list(databin)\n",
    "databin1 = databin.drop(['target'],1)\n",
    "col_name=\"target\"\n",
    "first_col = databin.pop(col_name)\n",
    "databin1.insert(45,col_name, first_col)\n",
    "databin = databin1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data and creating plus and minus contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contexts(train):\n",
    "    return train[train[:, -1] == 1][:, :-1], train[train[:, -1] == 0][:, :-1]\n",
    "def split(data, seed=1):\n",
    "    splits = []\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    sp = 4\n",
    "    split_size = data.shape[0] // sp\n",
    "    samples = data.to_numpy()\n",
    "    np.random.shuffle(samples)\n",
    "    for i in range(sp):\n",
    "        train = np.concatenate([samples[:i*split_size], samples[(i+1)*split_size:]], axis=0)\n",
    "        test = samples[i*split_size:(i+1)*split_size]\n",
    "        splits.append([train, test])\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCA algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a simple implementation of FCA logic based on plus and minus contexts. For any object, if the number of intersections with our object with plus context is more than with minus one, then the object is classified as positive, otherwise as negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FCA_1(databin):\n",
    "    splits = split(databin, seed=1)\n",
    "    TPl = []\n",
    "    FPl = []\n",
    "    TNl = []\n",
    "    FNl = []\n",
    "    def Intersect(s, context1, context2):\n",
    "        intersections = 0\n",
    "        for i in context1:\n",
    "            intersections += ((s * i).sum())\n",
    "        return intersections\n",
    "    for train, test in splits:\n",
    "        plus_train, minus_train = contexts(train)\n",
    "        plus_test, minus_test = contexts(test)\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        for s in plus_test:\n",
    "            plus = Intersect(s, plus_train, minus_train)\n",
    "            minus = Intersect(s, minus_train, plus_train)\n",
    "            if plus > minus:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        TPl.append(tp)\n",
    "        FPl.append(fp)\n",
    "        tn = 0\n",
    "        fn = 0\n",
    "        for s in minus_test:\n",
    "            plus = Intersect(s, plus_train, minus_train)\n",
    "            minus = Intersect(s, minus_train, plus_train)\n",
    "            if minus > plus:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        TNl.append(tn)\n",
    "        FNl.append(fn)\n",
    "    TP = sum(TPl)\n",
    "    FP = sum(FPl)\n",
    "    TN = sum(TNl)\n",
    "    FN = sum(FNl)\n",
    "    total = TP + FP + TN + FN\n",
    "    print (\"True positive:\", TP ,\"\\n\" \n",
    "        \"True Negative:\", TN,\"\\n\"\n",
    "        \"False Positive:\", FP,\"\\n\"\n",
    "        \"False Negative:\", FN,\"\\n\"\n",
    "        \"True Positive Rate:\", float(TP) / (TP + FN),\"\\n\"\n",
    "        \"True Negative Rate:\", float(TN) / (TN + FP),\"\\n\"\n",
    "        \"Negative Predictive Value:\", float(TN) / (TN + FN),\"\\n\"\n",
    "        \"False Positive Rate:\",float(FP) / (FP + TN),\"\\n\"\n",
    "        \"False Discovery Rate:\",float(FP) / (TP + FP),\"\\n\"\n",
    "        \"Accuracy:\" ,(TP+TN)/total,\"\\n\"\n",
    "        \"Precision:\" ,TP/(TP + FP),\"\\n\"\n",
    "        \"Recall:\" ,TP/(TP + FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 157 \n",
      "True Negative: 83 \n",
      "False Positive: 6 \n",
      "False Negative: 54 \n",
      "True Positive Rate: 0.7440758293838863 \n",
      "True Negative Rate: 0.9325842696629213 \n",
      "Negative Predictive Value: 0.6058394160583942 \n",
      "False Positive Rate: 0.06741573033707865 \n",
      "False Discovery Rate: 0.03680981595092025 \n",
      "Accuracy: 0.8 \n",
      "Precision: 0.9631901840490797 \n",
      "Recall: 0.7440758293838863\n"
     ]
    }
   ],
   "source": [
    "FCA_1(databin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another implementation of FCA follows the logic of dividing the number of intersections with one or another context by the the number of all elements in the context. Thus, we can evade the problem of differences of contexts' sizes and get more correct results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FCA_2(databin):\n",
    "    splits = split(databin, seed=1)\n",
    "    TPl = []\n",
    "    FPl = []\n",
    "    TNl = []\n",
    "    FNl = []\n",
    "    def Intersect(s, context1, context2):\n",
    "        intersections = 0\n",
    "        for i in context1:\n",
    "            intersections += ((s * i).sum() / context1.shape[0])\n",
    "        return intersections\n",
    "    for train, test in splits:\n",
    "        plus_train, minus_train = contexts(train)\n",
    "        plus_test, minus_test = contexts(test)\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        for s in plus_test:\n",
    "            plus = Intersect(s, plus_train, minus_train)\n",
    "            minus = Intersect(s, minus_train, plus_train)\n",
    "            if plus > minus:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        TPl.append(tp)\n",
    "        FPl.append(fp)\n",
    "        tn = 0\n",
    "        fn = 0\n",
    "        for s in minus_test:\n",
    "            plus = Intersect(s, plus_train, minus_train)\n",
    "            minus = Intersect(s, minus_train, plus_train)\n",
    "            if minus > plus:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        TNl.append(tn)\n",
    "        FNl.append(fn)\n",
    "    TP = sum(TPl)\n",
    "    FP = sum(FPl)\n",
    "    TN = sum(TNl)\n",
    "    FN = sum(FNl)\n",
    "    total = TP + FP + TN + FN\n",
    "    print (\"True positive:\", TP ,\"\\n\" \n",
    "        \"True Negative:\", TN,\"\\n\"\n",
    "        \"False Positive:\", FP,\"\\n\"\n",
    "        \"False Negative:\", FN,\"\\n\"\n",
    "        \"True Positive Rate:\", float(TP) / (TP + FN),\"\\n\"\n",
    "        \"True Negative Rate:\", float(TN) / (TN + FP),\"\\n\"\n",
    "        \"Negative Predictive Value:\", float(TN) / (TN + FN),\"\\n\"\n",
    "        \"False Positive Rate:\",float(FP) / (FP + TN),\"\\n\"\n",
    "        \"False Discovery Rate:\",float(FP) / (TP + FP),\"\\n\"\n",
    "        \"Accuracy:\" ,(TP+TN)/total,\"\\n\"\n",
    "        \"Precision:\" ,TP/(TP + FP),\"\\n\"\n",
    "        \"Recall:\" ,TP/(TP + FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 143 \n",
      "True Negative: 113 \n",
      "False Positive: 22 \n",
      "False Negative: 22 \n",
      "True Positive Rate: 0.8666666666666667 \n",
      "True Negative Rate: 0.837037037037037 \n",
      "Negative Predictive Value: 0.837037037037037 \n",
      "False Positive Rate: 0.16296296296296298 \n",
      "False Discovery Rate: 0.13333333333333333 \n",
      "Accuracy: 0.8533333333333334 \n",
      "Precision: 0.8666666666666667 \n",
      "Recall: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "FCA_2(databin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State of art algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(databin):\n",
    "    splits = split(databin, seed=1)\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    for train, test in splits:\n",
    "        plus_train, minus_train = contexts(train)\n",
    "        plus_test, minus_test = contexts(test)\n",
    "        X = np.concatenate([plus_train, minus_train])\n",
    "        Y = np.concatenate([np.ones(shape=(plus_train.shape[0],)), np.zeros(shape=(minus_train.shape[0],))])\n",
    "        clf = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "        clf = clf.fit(X, Y)\n",
    "    TP= int(clf.predict(plus_test).sum())\n",
    "    FN=(1 - clf.predict(plus_test)).sum()\n",
    "    TN=(1 - clf.predict(minus_test)).sum()\n",
    "    FP= int(clf.predict(minus_test).sum())\n",
    "    total = TP + FN + TN + FP\n",
    "    print (\"True positive:\", TP ,\"\\n\" \n",
    "    \"True Negative:\", TN,\"\\n\"\n",
    "    \"False Positive:\", FP,\"\\n\"\n",
    "    \"False Negative:\", FN,\"\\n\"\n",
    "    \"True Positive Rate:\", float(TP) / (TP + FN),\"\\n\"\n",
    "    \"True Negative Rate:\", float(TN) / (TN + FP),\"\\n\"\n",
    "    \"Negative Predictive Value:\", float(TN) / (TN + FN),\"\\n\"\n",
    "    \"False Positive Rate:\",float(FP) / (FP + TN),\"\\n\"\n",
    "    \"False Discovery Rate:\",float(FP) / (TP + FP),\"\\n\"\n",
    "    \"Accuracy:\" ,(TP+TN)/total,\"\\n\"\n",
    "    \"Precision:\" ,TP/(TP + FP),\"\\n\"\n",
    "    \"Recall:\" ,TP/(TP + FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 37 \n",
      "True Negative: 25.0 \n",
      "False Positive: 7 \n",
      "False Negative: 6.0 \n",
      "True Positive Rate: 0.8604651162790697 \n",
      "True Negative Rate: 0.78125 \n",
      "Negative Predictive Value: 0.8064516129032258 \n",
      "False Positive Rate: 0.21875 \n",
      "False Discovery Rate: 0.1590909090909091 \n",
      "Accuracy: 0.8266666666666667 \n",
      "Precision: 0.8409090909090909 \n",
      "Recall: 0.8604651162790697\n"
     ]
    }
   ],
   "source": [
    "RandomForest(databin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Knn(databin):\n",
    "    splits = split(databin, seed=1)\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    for train, test in splits:\n",
    "        plus_train, minus_train = contexts(train)\n",
    "        plus_test, minus_test = contexts(test)\n",
    "        X = np.concatenate([plus_train, minus_train])\n",
    "        Y = np.concatenate([np.ones(shape=(plus_train.shape[0],)), np.zeros(shape=(minus_train.shape[0],))])\n",
    "        clf = KNeighborsClassifier(n_neighbors=5)\n",
    "        clf = clf.fit(X, Y)\n",
    "    TP= int(clf.predict(plus_test).sum())\n",
    "    FN=(1 - clf.predict(plus_test)).sum()\n",
    "    TN=(1 - clf.predict(minus_test)).sum()\n",
    "    FP= int(clf.predict(minus_test).sum())\n",
    "    total = TP + FN + TN + FP\n",
    "    print (\"True positive:\", TP ,\"\\n\" \n",
    "    \"True Negative:\", TN,\"\\n\"\n",
    "    \"False Positive:\", FP,\"\\n\"\n",
    "    \"False Negative:\", FN,\"\\n\"\n",
    "    \"True Positive Rate:\", float(TP) / (TP + FN),\"\\n\"\n",
    "    \"True Negative Rate:\", float(TN) / (TN + FP),\"\\n\"\n",
    "    \"Negative Predictive Value:\", float(TN) / (TN + FN),\"\\n\"\n",
    "    \"False Positive Rate:\",float(FP) / (FP + TN),\"\\n\"\n",
    "    \"False Discovery Rate:\",float(FP) / (TP + FP),\"\\n\"\n",
    "    \"Accuracy:\" ,(TP+TN)/total,\"\\n\"\n",
    "    \"Precision:\" ,TP/(TP + FP),\"\\n\"\n",
    "    \"Recall:\" ,TP/(TP + FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 36 \n",
      "True Negative: 25.0 \n",
      "False Positive: 11 \n",
      "False Negative: 3.0 \n",
      "True Positive Rate: 0.9230769230769231 \n",
      "True Negative Rate: 0.6944444444444444 \n",
      "Negative Predictive Value: 0.8928571428571429 \n",
      "False Positive Rate: 0.3055555555555556 \n",
      "False Discovery Rate: 0.23404255319148937 \n",
      "Accuracy: 0.8133333333333334 \n",
      "Precision: 0.7659574468085106 \n",
      "Recall: 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "Knn(databin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegression(databin):   \n",
    "    splits = split(databin, seed=1)\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    for train, test in splits:\n",
    "        plus_train, minus_train = contexts(train)\n",
    "        plus_test, minus_test = contexts(test)\n",
    "        X = np.concatenate([plus_train, minus_train])\n",
    "        Y = np.concatenate([np.ones(shape=(plus_train.shape[0],)), np.zeros(shape=(minus_train.shape[0],))])\n",
    "        clf = LogisticRegression(random_state=2)\n",
    "        clf = clf.fit(X, Y)\n",
    "    TP= int(clf.predict(plus_test).sum())\n",
    "    FN=(1 - clf.predict(plus_test)).sum()\n",
    "    TN=(1 - clf.predict(plus_test)).sum()\n",
    "    FP= int(clf.predict(minus_test).sum())\n",
    "    total = TP + FN + TN + FP\n",
    "    print (\"True positive:\", TP ,\"\\n\" \n",
    "    \"True Negative:\", TN,\"\\n\"\n",
    "    \"False Positive:\", FP,\"\\n\"\n",
    "    \"False Negative:\", FN,\"\\n\"\n",
    "    \"True Positive Rate:\", float(TP) / (TP + FN),\"\\n\"\n",
    "    \"True Negative Rate:\", float(TN) / (TN + FP),\"\\n\"\n",
    "    \"Negative Predictive Value:\", float(TN) / (TN + FN),\"\\n\"\n",
    "    \"False Positive Rate:\",float(FP) / (FP + TN),\"\\n\"\n",
    "    \"False Discovery Rate:\",float(FP) / (TP + FP),\"\\n\"\n",
    "    \"Accuracy:\" ,(TP+TN)/total,\"\\n\"\n",
    "    \"Precision:\" ,TP/(TP + FP),\"\\n\"\n",
    "    \"Recall:\" ,TP/(TP + FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 25 \n",
      "True Negative: 12.0 \n",
      "False Positive: 9 \n",
      "False Negative: 12.0 \n",
      "True Positive Rate: 0.6756756756756757 \n",
      "True Negative Rate: 0.5714285714285714 \n",
      "Negative Predictive Value: 0.5 \n",
      "False Positive Rate: 0.42857142857142855 \n",
      "False Discovery Rate: 0.2647058823529412 \n",
      "Accuracy: 0.6379310344827587 \n",
      "Precision: 0.7352941176470589 \n",
      "Recall: 0.6756756756756757\n"
     ]
    }
   ],
   "source": [
    "LogisticRegression(databin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying my own dataset on coronavirus behavioral patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independent variables are: <br >  <br > \n",
    "Believe in covid-19 <br >\n",
    "Frequency of meetings with friends <br >\n",
    "Frequency of hands washing <br >\n",
    "Believe that covid-19 will affect the person <br >\n",
    "Probability that friend will be offended by lack of physical contact <br >\n",
    "Frequency of making an official pass <br >\n",
    "Frequency if joking about covid <br >\n",
    "Frequency of going to public places <br > <br > \n",
    "Target is the frequency of going out, I recoded this variable into a dichotomic one, 1-5 frequency was transformed into 0 and 6-10 - into 1. \n",
    "\n",
    "It will be also necessary to compare these models with non-binary raw data taken as independent variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_spss('Corona.sav', convert_categoricals=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial = pd.read_spss('Corona.sav', convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = pd.read_spss('Corona.sav', convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#Let's recode our variables, all of them excpet for gender are scale\n",
    "positive = 'gndr_1'\n",
    "negative = 'gndr_0'\n",
    "df[positive] = 0\n",
    "df[positive][df['gndr'] == 1] = 1\n",
    "df[negative] = 0\n",
    "df[negative][df['gndr'] == 0] = 1\n",
    "df = df.drop(['gndr'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "target = 'target'\n",
    "df[target] = 0\n",
    "df[target][df['chastoulitsa'] == 6] = 1\n",
    "df[target][df['chastoulitsa'] == 7] = 1\n",
    "df[target][df['chastoulitsa'] == 8] = 1\n",
    "df[target][df['chastoulitsa'] == 9] = 1\n",
    "df[target][df['chastoulitsa'] == 10] = 1\n",
    "df[target][df['chastoulitsa'] == 1] = 0\n",
    "df[target][df['chastoulitsa'] == 2] = 0\n",
    "df[target][df['chastoulitsa'] == 3] = 0\n",
    "df[target][df['chastoulitsa'] == 4] = 0\n",
    "df[target][df['chastoulitsa'] == 5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\anyur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "interval_parameters = ['age', 'vera', 'vstrechdruz', 'mitruki', 'coronakosnetsya', 'drugobid',\n",
    "                     'propusk', 'shutka', 'obshestvmesta']\n",
    "for feature in interval_parameters:\n",
    "    bins = sorted({x for x in pd.cut(df[feature], 5)})\n",
    "    for bucket in range(len(bins)):\n",
    "        column_name = '{}_{}'.format(feature, bucket+1)\n",
    "        df[column_name] = 0\n",
    "        df[column_name][(df[feature] > bins[bucket].left) & (df[feature] <= bins[bucket].right)] = 1\n",
    "        \n",
    "df = df.drop(interval_parameters, axis='columns')\n",
    "#df = df[[x for x in data.columns if x != 'target'] + ['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(df)\n",
    "df1 = df.drop(['target'],1)\n",
    "col_name=\"target\"\n",
    "first_col = df.pop(col_name)\n",
    "df1.insert(48,col_name, first_col)\n",
    "df = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('chastoulitsa', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 226 \n",
      "True Negative: 130 \n",
      "False Positive: 62 \n",
      "False Negative: 122 \n",
      "True Positive Rate: 0.6494252873563219 \n",
      "True Negative Rate: 0.6770833333333334 \n",
      "Negative Predictive Value: 0.5158730158730159 \n",
      "False Positive Rate: 0.3229166666666667 \n",
      "False Discovery Rate: 0.2152777777777778 \n",
      "Accuracy: 0.6592592592592592 \n",
      "Precision: 0.7847222222222222 \n",
      "Recall: 0.6494252873563219\n"
     ]
    }
   ],
   "source": [
    "FCA_1(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 136 \n",
      "True Negative: 218 \n",
      "False Positive: 152 \n",
      "False Negative: 34 \n",
      "True Positive Rate: 0.8 \n",
      "True Negative Rate: 0.5891891891891892 \n",
      "Negative Predictive Value: 0.8650793650793651 \n",
      "False Positive Rate: 0.41081081081081083 \n",
      "False Discovery Rate: 0.5277777777777778 \n",
      "Accuracy: 0.6555555555555556 \n",
      "Precision: 0.4722222222222222 \n",
      "Recall: 0.8\n"
     ]
    }
   ],
   "source": [
    "FCA_2(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 51 \n",
      "True Negative: 45.0 \n",
      "False Positive: 23 \n",
      "False Negative: 16.0 \n",
      "True Positive Rate: 0.7611940298507462 \n",
      "True Negative Rate: 0.6617647058823529 \n",
      "Negative Predictive Value: 0.7377049180327869 \n",
      "False Positive Rate: 0.3382352941176471 \n",
      "False Discovery Rate: 0.3108108108108108 \n",
      "Accuracy: 0.7111111111111111 \n",
      "Precision: 0.6891891891891891 \n",
      "Recall: 0.7611940298507462\n"
     ]
    }
   ],
   "source": [
    "RandomForest(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 47 \n",
      "True Negative: 48.0 \n",
      "False Positive: 22 \n",
      "False Negative: 18.0 \n",
      "True Positive Rate: 0.7230769230769231 \n",
      "True Negative Rate: 0.6857142857142857 \n",
      "Negative Predictive Value: 0.7272727272727273 \n",
      "False Positive Rate: 0.3142857142857143 \n",
      "False Discovery Rate: 0.3188405797101449 \n",
      "Accuracy: 0.7037037037037037 \n",
      "Precision: 0.6811594202898551 \n",
      "Recall: 0.7230769230769231\n"
     ]
    }
   ],
   "source": [
    "Knn(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 48 \n",
      "True Negative: 27.0 \n",
      "False Positive: 19 \n",
      "False Negative: 27.0 \n",
      "True Positive Rate: 0.64 \n",
      "True Negative Rate: 0.5869565217391305 \n",
      "Negative Predictive Value: 0.5 \n",
      "False Positive Rate: 0.41304347826086957 \n",
      "False Discovery Rate: 0.2835820895522388 \n",
      "Accuracy: 0.6198347107438017 \n",
      "Precision: 0.7164179104477612 \n",
      "Recall: 0.64\n"
     ]
    }
   ],
   "source": [
    "LogisticRegression(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCA â„–3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's make the algorithm more strict introducing the rule for determining the positive or negative class. If the proportion of plus intersections over minus intersections exceeds some value then it will be classified as positive. Now being just less or more is not enough. The same logic will be applied to the minus context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FCA_3(databin, P, M):\n",
    "    splits = split(databin, seed=1)\n",
    "    TPl = []\n",
    "    FPl = []\n",
    "    TNl = []\n",
    "    FNl = []\n",
    "    def Intersect(s, context1, context2):\n",
    "        intersections = 0\n",
    "        for i in context1:\n",
    "            intersections += ((s * i).sum() / context1.shape[0])\n",
    "        return intersections\n",
    "    for train, test in splits:\n",
    "        plus_train, minus_train = contexts(train)\n",
    "        plus_test, minus_test = contexts(test)\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        for s in plus_test:\n",
    "            plus = Intersect(s, plus_train, minus_train)\n",
    "            minus = Intersect(s, minus_train, plus_train)\n",
    "            if plus/minus > P:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        TPl.append(tp)\n",
    "        FPl.append(fp)\n",
    "        tn = 0\n",
    "        fn = 0\n",
    "        for s in minus_test:\n",
    "            plus = Intersect(s, plus_train, minus_train)\n",
    "            minus = Intersect(s, minus_train, plus_train)\n",
    "            if minus/plus > M:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        TNl.append(tn)\n",
    "        FNl.append(fn)\n",
    "    TP = sum(TPl)\n",
    "    FP = sum(FPl)\n",
    "    TN = sum(TNl)\n",
    "    FN = sum(FNl)\n",
    "    total = TP + FP + TN + FN\n",
    "    print (\"True positive:\", TP ,\"\\n\" \n",
    "        \"True Negative:\", TN,\"\\n\"\n",
    "        \"False Positive:\", FP,\"\\n\"\n",
    "        \"False Negative:\", FN,\"\\n\"\n",
    "        \"True Positive Rate:\", float(TP) / (TP + FN),\"\\n\"\n",
    "        \"True Negative Rate:\", float(TN) / (TN + FP),\"\\n\"\n",
    "        \"Negative Predictive Value:\", float(TN) / (TN + FN),\"\\n\"\n",
    "        \"False Positive Rate:\",float(FP) / (FP + TN),\"\\n\"\n",
    "        \"False Discovery Rate:\",float(FP) / (TP + FP),\"\\n\"\n",
    "        \"Accuracy:\" ,(TP+TN)/total,\"\\n\"\n",
    "        \"Precision:\" ,TP/(TP + FP),\"\\n\"\n",
    "        \"Recall:\" ,TP/(TP + FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 129 \n",
      "True Negative: 98 \n",
      "False Positive: 35 \n",
      "False Negative: 38 \n",
      "True Positive Rate: 0.7724550898203593 \n",
      "True Negative Rate: 0.7368421052631579 \n",
      "Negative Predictive Value: 0.7205882352941176 \n",
      "False Positive Rate: 0.2631578947368421 \n",
      "False Discovery Rate: 0.21341463414634146 \n",
      "Accuracy: 0.7566666666666667 \n",
      "Precision: 0.7865853658536586 \n",
      "Recall: 0.7724550898203593\n"
     ]
    }
   ],
   "source": [
    "FCA_3(databin, 1.1 , 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 106 \n",
      "True Negative: 76 \n",
      "False Positive: 58 \n",
      "False Negative: 60 \n",
      "True Positive Rate: 0.6385542168674698 \n",
      "True Negative Rate: 0.5671641791044776 \n",
      "Negative Predictive Value: 0.5588235294117647 \n",
      "False Positive Rate: 0.43283582089552236 \n",
      "False Discovery Rate: 0.35365853658536583 \n",
      "Accuracy: 0.6066666666666667 \n",
      "Precision: 0.6463414634146342 \n",
      "Recall: 0.6385542168674698\n"
     ]
    }
   ],
   "source": [
    "FCA_3(databin, 1.25, 1.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less strict requirements for minus/plus, to have more correct negative classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 102 \n",
      "True Negative: 97 \n",
      "False Positive: 61 \n",
      "False Negative: 40 \n",
      "True Positive Rate: 0.7183098591549296 \n",
      "True Negative Rate: 0.6139240506329114 \n",
      "Negative Predictive Value: 0.708029197080292 \n",
      "False Positive Rate: 0.3860759493670886 \n",
      "False Discovery Rate: 0.37423312883435583 \n",
      "Accuracy: 0.6633333333333333 \n",
      "Precision: 0.6257668711656442 \n",
      "Recall: 0.7183098591549296\n"
     ]
    }
   ],
   "source": [
    "FCA_3(databin, 1.25 , 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 158 \n",
      "True Negative: 113 \n",
      "False Positive: 6 \n",
      "False Negative: 23 \n",
      "True Positive Rate: 0.8729281767955801 \n",
      "True Negative Rate: 0.9495798319327731 \n",
      "Negative Predictive Value: 0.8308823529411765 \n",
      "False Positive Rate: 0.05042016806722689 \n",
      "False Discovery Rate: 0.036585365853658534 \n",
      "Accuracy: 0.9033333333333333 \n",
      "Precision: 0.9634146341463414 \n",
      "Recall: 0.8729281767955801\n"
     ]
    }
   ],
   "source": [
    "FCA_3(databin, 0.8, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coronavirus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 288 \n",
      "True Negative: 221 \n",
      "False Positive: 0 \n",
      "False Negative: 31 \n",
      "True Positive Rate: 0.9028213166144201 \n",
      "True Negative Rate: 1.0 \n",
      "Negative Predictive Value: 0.876984126984127 \n",
      "False Positive Rate: 0.0 \n",
      "False Discovery Rate: 0.0 \n",
      "Accuracy: 0.9425925925925925 \n",
      "Precision: 1.0 \n",
      "Recall: 0.9028213166144201\n"
     ]
    }
   ],
   "source": [
    "FCA_3(df, 0.7, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
